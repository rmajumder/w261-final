{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w261 Final Project - Clickthrough Rate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import when  \n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "app_name = \"w261_final_rishi\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "\n",
    "train_tmp_rdd = sc.textFile('gs://w261hw5rishi/projdata/dac/test.txt')\n",
    "\n",
    "rdd_train = train_tmp_rdd.map(lambda r : r.split('\\t'))\n",
    "\n",
    "df_train = rdd_train.toDF()\n",
    "\n",
    "#df_test = spark.read.csv('data/dac/test.small.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_train.take(5), columns=df_train.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_val(t_data):\n",
    "    #Fill missing values - numerical\n",
    "    return t_data.na.fill(0)\n",
    "\n",
    "\n",
    "def get_columns(t_data):\n",
    "    #Store the original columns\n",
    "    cols = t_data.columns\n",
    "    \n",
    "    #Get numeric and categorical column names\n",
    "    numericCols = t_data.columns[1:14]\n",
    "    categoricalColumns = t_data.columns[16:41]\n",
    "    \n",
    "    return cols, numericCols, categoricalColumns\n",
    "\n",
    "def match_test_cols_with_train_cols(t_data):\n",
    "    \n",
    "    new_names = []\n",
    "    \n",
    "    #rename cols to match train data\n",
    "    for c in t_data.columns:\n",
    "        curr_pos = c.split('_')[1]\n",
    "        new_names.append('_' + str(int(curr_pos) + 1))\n",
    "   \n",
    "    t_data = t_data.toDF(*new_names)\n",
    "    \n",
    "    #include a dummy output col\n",
    "    t_data = t_data.withColumn(\"_1\", lit(0))\n",
    "    \n",
    "    return t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_string_indexer_vector_assm_pipeline_stages(num_cols, cat_cols):\n",
    "    stages = []\n",
    "    indexerCols = []\n",
    "\n",
    "    for categoricalCol in cat_cols:\n",
    "        indexerCol = categoricalCol + \"Index\"\n",
    "        indexer = StringIndexer(inputCol=categoricalCol, outputCol= indexerCol).setHandleInvalid(\"keep\")\n",
    "        stages += [indexer]\n",
    "        indexerCols.append(indexerCol)\n",
    "\n",
    "    \n",
    "    label_stringIdx = StringIndexer(inputCol = '_1', outputCol = 'output')\n",
    "    stages += [label_stringIdx]\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=indexerCols + num_cols, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    \n",
    "    return stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_transformation_pipeline_stages(t_data, cols, stages):\n",
    "    pipeline = Pipeline(stages = stages)\n",
    "    pipelineModel = pipeline.fit(t_data)\n",
    "    t_data = pipelineModel.transform(t_data)\n",
    "\n",
    "    selectedCols = ['output', 'features'] + cols\n",
    "    t_data = t_data.select(selectedCols)\n",
    "        \n",
    "    return t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_standard_scaler(t_data):\n",
    "    standardscaler=StandardScaler().setInputCol(\"features\").setOutputCol(\"scaled_features\")\n",
    "    t_data = standardscaler.fit(t_data).transform(t_data)\n",
    "    \n",
    "    return t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "\n",
    "def train_test_split(t_data):\n",
    "    train, test = t_data.randomSplit([0.7, 0.3], seed = 2019)\n",
    "    print(\"Training Dataset Count: \" + str(train.count()))\n",
    "    print(\"Test Dataset Count: \" + str(test.count()))\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(t_data):\n",
    "    #Feature selection\n",
    "    css = ChiSqSelector(featuresCol='scaled_features',outputCol='Aspect',labelCol='output',fpr=0.05)\n",
    "    t_data=css.fit(t_data).transform(t_data)\n",
    "    \n",
    "    return t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imbalance check - train only\n",
    "\n",
    "def get_balance_weight_ratio_data(t_data):\n",
    "    dataset_size=float(t_data.select(\"output\").count())\n",
    "    numPositives=t_data.select(\"output\").where('output == 1').count()\n",
    "    per_ones=(float(numPositives)/float(dataset_size))*100\n",
    "    numNegatives=float(dataset_size-numPositives)\n",
    "    \n",
    "    #Rebalance data\n",
    "    BalancingRatio = numNegatives/dataset_size\n",
    "    \n",
    "    return t_data.withColumn(\"classWeights\", when(t_data.output == 1,BalancingRatio).otherwise(1-BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perf_summary(trainingSummary):\n",
    "    print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))\n",
    "    \n",
    "    accuracy = trainingSummary.accuracy\n",
    "    falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "    truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "    fMeasure = trainingSummary.weightedFMeasure()\n",
    "    precision = trainingSummary.weightedPrecision\n",
    "    recall = trainingSummary.weightedRecall\n",
    "    print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "          % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perf_eval(predictions):\n",
    "    predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"probability\",\"output\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol = 'output')\n",
    "    print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression(tn_data):\n",
    "    lr = LogisticRegression(maxIter=10, featuresCol=\"Aspect\", labelCol=\"output\", \n",
    "                            weightCol=\"classWeights\", predictionCol=\"prediction\")\n",
    "    # Fit the model\n",
    "    lrModel = lr.fit(tn_data)\n",
    "\n",
    "    predict_train=lrModel.transform(tn_data)\n",
    "    #predict_test=lrModel.transform(ts_data)\n",
    "    \n",
    "    trainingSummary = lrModel.summary\n",
    "    \n",
    "    print_perf_summary(trainingSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest_algorithm(tn_data, ts_data):\n",
    "    rf = RandomForestClassifier(numTrees=10, featuresCol=\"scaled_features\", labelCol=\"output\", predictionCol=\"prediction\")\n",
    "    rfModel = rf.fit(tn_data)\n",
    "    predictions = rfModel.transform(ts_data)\n",
    "    \n",
    "    print_perf_eval(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradient_boost(tn_data, ts_data):\n",
    "    gbt = GBTClassifier(maxIter=10, featuresCol=\"scaled_features\", labelCol=\"output\", predictionCol=\"prediction\")\n",
    "    gbtModel = gbt.fit(tn_data)\n",
    "    predictions = gbtModel.transform(ts_data)\n",
    "    \n",
    "    print_perf_eval(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lsvc(tn_data, ts_data):\n",
    "    sv = LinearSVC(maxIter=10, regParam=0.1,\n",
    "                     featuresCol=\"scaled_features\", labelCol=\"output\", predictionCol=\"prediction\")\n",
    "    svModel = sv.fit(tn_data)\n",
    "    predictions = svModel.transform(ts_data)\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol = 'output')\n",
    "    print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing values\n",
    "df_train = fill_missing_val(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get columns and stages\n",
    "cols, num_cols, cat_cols = get_columns(df_train)\n",
    "stages = create_string_indexer_vector_assm_pipeline_stages(num_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_train = run_transformation_pipeline_stages(df_train, cols, stages)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_train = run_standard_scaler(df_train)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_train = feature_selection(df_train)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "train, test = train_test_split(df_train)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "train = get_balance_weight_ratio_data(train)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "run_logistic_regression(train)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "run_random_forest_algorithm(train, test)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "run_gradient_boost(train, test)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "run_lsvc(train, test)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}