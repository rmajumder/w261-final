{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import when  \n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "import pyspark.mllib\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SQLContext as hv\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = !pwd\n",
    "PWD = PWD[0]\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"project\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project/train_tiny.csv\n"
     ]
    }
   ],
   "source": [
    "!ls project/train_tiny.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny = spark.read.csv('project/train_tiny.csv', header = True, inferSchema = True)\n",
    "rdd_train = sc.textFile('project/train.txt').map(lambda r : r.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema=df_tiny.schema\n",
    "cols = df_tiny.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=rdd_train.toDF().limit(200).cache()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1='0', _2='1', _3='1', _4='5', _5='0', _6='1382', _7='4', _8='15', _9='2', _10='181', _11='1', _12='2', _13='', _14='2', _15='68fd1e64', _16='80e26c9b', _17='fb936136', _18='7b4723c4', _19='25c83c98', _20='7e0ccccf', _21='de7995b8', _22='1f89b562', _23='a73ee510', _24='a8cd5504', _25='b2cb9c98', _26='37c9c164', _27='2824a5f6', _28='1adce6ef', _29='8ba8b39a', _30='891b62e7', _31='e5ba7672', _32='f54016b9', _33='21ddcdc9', _34='b1252a9d', _35='07b5194c', _36='', _37='3a171ecb', _38='c5c50484', _39='e8b83407', _40='9727dd16')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bkp=df\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_4</th>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_6</th>\n",
       "      <td>1382</td>\n",
       "      <td>102</td>\n",
       "      <td>767</td>\n",
       "      <td>4392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_7</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_8</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_10</th>\n",
       "      <td>181</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_12</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_13</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_14</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_15</th>\n",
       "      <td>68fd1e64</td>\n",
       "      <td>68fd1e64</td>\n",
       "      <td>287e684f</td>\n",
       "      <td>68fd1e64</td>\n",
       "      <td>8cf07265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_16</th>\n",
       "      <td>80e26c9b</td>\n",
       "      <td>f0cf0024</td>\n",
       "      <td>0a519c5c</td>\n",
       "      <td>2c16a946</td>\n",
       "      <td>ae46a29d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_17</th>\n",
       "      <td>fb936136</td>\n",
       "      <td>6f67f7e5</td>\n",
       "      <td>02cf9876</td>\n",
       "      <td>a9a87e68</td>\n",
       "      <td>c81688bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_18</th>\n",
       "      <td>7b4723c4</td>\n",
       "      <td>41274cd7</td>\n",
       "      <td>c18be181</td>\n",
       "      <td>2e17d6f6</td>\n",
       "      <td>f922efad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_19</th>\n",
       "      <td>25c83c98</td>\n",
       "      <td>25c83c98</td>\n",
       "      <td>25c83c98</td>\n",
       "      <td>25c83c98</td>\n",
       "      <td>25c83c98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_20</th>\n",
       "      <td>7e0ccccf</td>\n",
       "      <td>fe6b92e5</td>\n",
       "      <td>7e0ccccf</td>\n",
       "      <td>fe6b92e5</td>\n",
       "      <td>13718bbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_21</th>\n",
       "      <td>de7995b8</td>\n",
       "      <td>922afcc0</td>\n",
       "      <td>c78204a1</td>\n",
       "      <td>2e8a689b</td>\n",
       "      <td>ad9fa255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_22</th>\n",
       "      <td>1f89b562</td>\n",
       "      <td>0b153874</td>\n",
       "      <td>0b153874</td>\n",
       "      <td>0b153874</td>\n",
       "      <td>0b153874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_23</th>\n",
       "      <td>a73ee510</td>\n",
       "      <td>a73ee510</td>\n",
       "      <td>a73ee510</td>\n",
       "      <td>a73ee510</td>\n",
       "      <td>a73ee510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_24</th>\n",
       "      <td>a8cd5504</td>\n",
       "      <td>2b53e5fb</td>\n",
       "      <td>3b08e48b</td>\n",
       "      <td>efea433b</td>\n",
       "      <td>5282c137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_25</th>\n",
       "      <td>b2cb9c98</td>\n",
       "      <td>4f1b46f3</td>\n",
       "      <td>5f5e6091</td>\n",
       "      <td>e51ddf94</td>\n",
       "      <td>e5d8af57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_26</th>\n",
       "      <td>37c9c164</td>\n",
       "      <td>623049e6</td>\n",
       "      <td>8fe001f4</td>\n",
       "      <td>a30567ca</td>\n",
       "      <td>66a76a26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_27</th>\n",
       "      <td>2824a5f6</td>\n",
       "      <td>d7020589</td>\n",
       "      <td>aa655a2f</td>\n",
       "      <td>3516f6e6</td>\n",
       "      <td>f06c53ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_28</th>\n",
       "      <td>1adce6ef</td>\n",
       "      <td>b28479f6</td>\n",
       "      <td>07d13a8f</td>\n",
       "      <td>07d13a8f</td>\n",
       "      <td>1adce6ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_29</th>\n",
       "      <td>8ba8b39a</td>\n",
       "      <td>e6c5b5cd</td>\n",
       "      <td>6dc710ed</td>\n",
       "      <td>18231224</td>\n",
       "      <td>8ff4b403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_30</th>\n",
       "      <td>891b62e7</td>\n",
       "      <td>c92f3b61</td>\n",
       "      <td>36103458</td>\n",
       "      <td>52b8680f</td>\n",
       "      <td>01adbab4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_31</th>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>1e88c74f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_32</th>\n",
       "      <td>f54016b9</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>3412118d</td>\n",
       "      <td>74ef3502</td>\n",
       "      <td>26b3c7a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_33</th>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_34</th>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>5840adea</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_35</th>\n",
       "      <td>07b5194c</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>6b3a5ca6</td>\n",
       "      <td>21c9516a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_36</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_37</th>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>32c7478e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_38</th>\n",
       "      <td>c5c50484</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>9117a34a</td>\n",
       "      <td>b34f3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_39</th>\n",
       "      <td>e8b83407</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_40</th>\n",
       "      <td>9727dd16</td>\n",
       "      <td>731c3655</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4\n",
       "_1          0         0         0         0         0\n",
       "_2          1         2         2                   3\n",
       "_3          1         0         0       893        -1\n",
       "_4          5        44         1                    \n",
       "_5          0         1        14                   0\n",
       "_6       1382       102       767      4392         2\n",
       "_7          4         8        89                   0\n",
       "_8         15         2         4         0         3\n",
       "_9          2         2         2         0         0\n",
       "_10       181         4       245         0         0\n",
       "_11         1         1         1                   1\n",
       "_12         2         1         3         0         1\n",
       "_13                             3                    \n",
       "_14         2         4        45                   0\n",
       "_15  68fd1e64  68fd1e64  287e684f  68fd1e64  8cf07265\n",
       "_16  80e26c9b  f0cf0024  0a519c5c  2c16a946  ae46a29d\n",
       "_17  fb936136  6f67f7e5  02cf9876  a9a87e68  c81688bb\n",
       "_18  7b4723c4  41274cd7  c18be181  2e17d6f6  f922efad\n",
       "_19  25c83c98  25c83c98  25c83c98  25c83c98  25c83c98\n",
       "_20  7e0ccccf  fe6b92e5  7e0ccccf  fe6b92e5  13718bbd\n",
       "_21  de7995b8  922afcc0  c78204a1  2e8a689b  ad9fa255\n",
       "_22  1f89b562  0b153874  0b153874  0b153874  0b153874\n",
       "_23  a73ee510  a73ee510  a73ee510  a73ee510  a73ee510\n",
       "_24  a8cd5504  2b53e5fb  3b08e48b  efea433b  5282c137\n",
       "_25  b2cb9c98  4f1b46f3  5f5e6091  e51ddf94  e5d8af57\n",
       "_26  37c9c164  623049e6  8fe001f4  a30567ca  66a76a26\n",
       "_27  2824a5f6  d7020589  aa655a2f  3516f6e6  f06c53ac\n",
       "_28  1adce6ef  b28479f6  07d13a8f  07d13a8f  1adce6ef\n",
       "_29  8ba8b39a  e6c5b5cd  6dc710ed  18231224  8ff4b403\n",
       "_30  891b62e7  c92f3b61  36103458  52b8680f  01adbab4\n",
       "_31  e5ba7672  07c540c4  8efede7f  1e88c74f  1e88c74f\n",
       "_32  f54016b9  b04e4670  3412118d  74ef3502  26b3c7a7\n",
       "_33  21ddcdc9  21ddcdc9                              \n",
       "_34  b1252a9d  5840adea                              \n",
       "_35  07b5194c  60f6221e  e587c466  6b3a5ca6  21c9516a\n",
       "_36                      ad3062eb                    \n",
       "_37  3a171ecb  3a171ecb  3a171ecb  3a171ecb  32c7478e\n",
       "_38  c5c50484  43f13e8b  3b183c5c  9117a34a  b34f3128\n",
       "_39  e8b83407  e8b83407                              \n",
       "_40  9727dd16  731c3655                              "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the original columns\n",
    "df_schema=df.schema\n",
    "cols = df.columns\n",
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_2', '_3', '_4', '_5', '_6', '_7', '_8', '_9', '_10', '_11', '_12', '_13', '_14', '_15']\n",
      "['_16', '_17', '_18', '_19', '_20', '_21', '_22', '_23', '_24', '_25', '_26', '_27', '_28', '_29', '_30', '_31', '_32', '_33', '_34', '_35', '_36', '_37', '_38', '_39', '_40']\n"
     ]
    }
   ],
   "source": [
    "#Get numeric and categorical column names\n",
    "numericCols = df.columns[1:15]\n",
    "categoricalColumns = df.columns[15:41]\n",
    "\n",
    "print(numericCols)\n",
    "print(categoricalColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_4</th>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_6</th>\n",
       "      <td>1382</td>\n",
       "      <td>102</td>\n",
       "      <td>767</td>\n",
       "      <td>4392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_7</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_8</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_10</th>\n",
       "      <td>181</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_12</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_14</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_15</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_16</th>\n",
       "      <td>80e26c9b</td>\n",
       "      <td>f0cf0024</td>\n",
       "      <td>0a519c5c</td>\n",
       "      <td>2c16a946</td>\n",
       "      <td>ae46a29d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_17</th>\n",
       "      <td>fb936136</td>\n",
       "      <td>6f67f7e5</td>\n",
       "      <td>02cf9876</td>\n",
       "      <td>a9a87e68</td>\n",
       "      <td>c81688bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_18</th>\n",
       "      <td>7b4723c4</td>\n",
       "      <td>41274cd7</td>\n",
       "      <td>c18be181</td>\n",
       "      <td>2e17d6f6</td>\n",
       "      <td>f922efad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_19</th>\n",
       "      <td>25c83c98</td>\n",
       "      <td>25c83c98</td>\n",
       "      <td>25c83c98</td>\n",
       "      <td>25c83c98</td>\n",
       "      <td>25c83c98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_20</th>\n",
       "      <td>7e0ccccf</td>\n",
       "      <td>fe6b92e5</td>\n",
       "      <td>7e0ccccf</td>\n",
       "      <td>fe6b92e5</td>\n",
       "      <td>13718bbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_21</th>\n",
       "      <td>de7995b8</td>\n",
       "      <td>922afcc0</td>\n",
       "      <td>c78204a1</td>\n",
       "      <td>2e8a689b</td>\n",
       "      <td>ad9fa255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_22</th>\n",
       "      <td>1f89b562</td>\n",
       "      <td>0b153874</td>\n",
       "      <td>0b153874</td>\n",
       "      <td>0b153874</td>\n",
       "      <td>0b153874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_23</th>\n",
       "      <td>a73ee510</td>\n",
       "      <td>a73ee510</td>\n",
       "      <td>a73ee510</td>\n",
       "      <td>a73ee510</td>\n",
       "      <td>a73ee510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_24</th>\n",
       "      <td>a8cd5504</td>\n",
       "      <td>2b53e5fb</td>\n",
       "      <td>3b08e48b</td>\n",
       "      <td>efea433b</td>\n",
       "      <td>5282c137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_25</th>\n",
       "      <td>b2cb9c98</td>\n",
       "      <td>4f1b46f3</td>\n",
       "      <td>5f5e6091</td>\n",
       "      <td>e51ddf94</td>\n",
       "      <td>e5d8af57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_26</th>\n",
       "      <td>37c9c164</td>\n",
       "      <td>623049e6</td>\n",
       "      <td>8fe001f4</td>\n",
       "      <td>a30567ca</td>\n",
       "      <td>66a76a26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_27</th>\n",
       "      <td>2824a5f6</td>\n",
       "      <td>d7020589</td>\n",
       "      <td>aa655a2f</td>\n",
       "      <td>3516f6e6</td>\n",
       "      <td>f06c53ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_28</th>\n",
       "      <td>1adce6ef</td>\n",
       "      <td>b28479f6</td>\n",
       "      <td>07d13a8f</td>\n",
       "      <td>07d13a8f</td>\n",
       "      <td>1adce6ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_29</th>\n",
       "      <td>8ba8b39a</td>\n",
       "      <td>e6c5b5cd</td>\n",
       "      <td>6dc710ed</td>\n",
       "      <td>18231224</td>\n",
       "      <td>8ff4b403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_30</th>\n",
       "      <td>891b62e7</td>\n",
       "      <td>c92f3b61</td>\n",
       "      <td>36103458</td>\n",
       "      <td>52b8680f</td>\n",
       "      <td>01adbab4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_31</th>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>1e88c74f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_32</th>\n",
       "      <td>f54016b9</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>3412118d</td>\n",
       "      <td>74ef3502</td>\n",
       "      <td>26b3c7a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_33</th>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_34</th>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_35</th>\n",
       "      <td>07b5194c</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>6b3a5ca6</td>\n",
       "      <td>21c9516a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_36</th>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_37</th>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>32c7478e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_38</th>\n",
       "      <td>c5c50484</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>9117a34a</td>\n",
       "      <td>b34f3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_39</th>\n",
       "      <td>e8b83407</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_40</th>\n",
       "      <td>9727dd16</td>\n",
       "      <td>731c3655</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "      <td>__Dummy__</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4\n",
       "_1           0          0          0          0          0\n",
       "_2           1          2          2          0          3\n",
       "_3           1          0          0        893         -1\n",
       "_4           5         44          1          0          0\n",
       "_5           0          1         14          0          0\n",
       "_6        1382        102        767       4392          2\n",
       "_7           4          8         89          0          0\n",
       "_8          15          2          4          0          3\n",
       "_9           2          2          2          0          0\n",
       "_10        181          4        245          0          0\n",
       "_11          1          1          1          0          1\n",
       "_12          2          1          3          0          1\n",
       "_13          0          0          3          0          0\n",
       "_14          2          4         45          0          0\n",
       "_15       None       None       None       None       None\n",
       "_16   80e26c9b   f0cf0024   0a519c5c   2c16a946   ae46a29d\n",
       "_17   fb936136   6f67f7e5   02cf9876   a9a87e68   c81688bb\n",
       "_18   7b4723c4   41274cd7   c18be181   2e17d6f6   f922efad\n",
       "_19   25c83c98   25c83c98   25c83c98   25c83c98   25c83c98\n",
       "_20   7e0ccccf   fe6b92e5   7e0ccccf   fe6b92e5   13718bbd\n",
       "_21   de7995b8   922afcc0   c78204a1   2e8a689b   ad9fa255\n",
       "_22   1f89b562   0b153874   0b153874   0b153874   0b153874\n",
       "_23   a73ee510   a73ee510   a73ee510   a73ee510   a73ee510\n",
       "_24   a8cd5504   2b53e5fb   3b08e48b   efea433b   5282c137\n",
       "_25   b2cb9c98   4f1b46f3   5f5e6091   e51ddf94   e5d8af57\n",
       "_26   37c9c164   623049e6   8fe001f4   a30567ca   66a76a26\n",
       "_27   2824a5f6   d7020589   aa655a2f   3516f6e6   f06c53ac\n",
       "_28   1adce6ef   b28479f6   07d13a8f   07d13a8f   1adce6ef\n",
       "_29   8ba8b39a   e6c5b5cd   6dc710ed   18231224   8ff4b403\n",
       "_30   891b62e7   c92f3b61   36103458   52b8680f   01adbab4\n",
       "_31   e5ba7672   07c540c4   8efede7f   1e88c74f   1e88c74f\n",
       "_32   f54016b9   b04e4670   3412118d   74ef3502   26b3c7a7\n",
       "_33   21ddcdc9   21ddcdc9  __Dummy__  __Dummy__  __Dummy__\n",
       "_34   b1252a9d   5840adea  __Dummy__  __Dummy__  __Dummy__\n",
       "_35   07b5194c   60f6221e   e587c466   6b3a5ca6   21c9516a\n",
       "_36  __Dummy__  __Dummy__   ad3062eb  __Dummy__  __Dummy__\n",
       "_37   3a171ecb   3a171ecb   3a171ecb   3a171ecb   32c7478e\n",
       "_38   c5c50484   43f13e8b   3b183c5c   9117a34a   b34f3128\n",
       "_39   e8b83407   e8b83407  __Dummy__  __Dummy__  __Dummy__\n",
       "_40   9727dd16   731c3655  __Dummy__  __Dummy__  __Dummy__"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_bkp\n",
    "from pyspark.sql.types import IntegerType,StringType\n",
    "from pyspark.sql.functions import udf\n",
    "#df = df.replace('',None)\n",
    "def rep_fu(x):\n",
    "    ret=x\n",
    "    if x.strip()=='':\n",
    "        ret=0\n",
    "    return ret  \n",
    "\n",
    "def rep_fu_string(x):\n",
    "    ret=x\n",
    "    if x.strip()=='':\n",
    "        ret='__Dummy__'\n",
    "    return ret\n",
    "\n",
    "rep_fun_string=udf(rep_fu_string)\n",
    "df = df.select(*[rep_fun_new(column).alias(column).cast(IntegerType()) if column in numericCols else column for column in df.columns])\n",
    "df = df.select(*[rep_fun_string(column).alias(column).cast(StringType()) if column in categoricalColumns else column for column in df.columns])\n",
    "pd.DataFrame(df.take(5),columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(df[df['_1'] == 0].count())\n",
    "print(df[df['_1'] == 1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "indexerCols = []\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    "    indexerCol = categoricalCol + \"Index\"\n",
    "    indexer = StringIndexer(inputCol=categoricalCol, outputCol= indexerCol).setHandleInvalid(\"keep\")\n",
    "    stages += [indexer]\n",
    "    indexerCols.append(indexerCol)\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = '_1', outputCol = 'output')\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assembler = VectorAssembler(inputCols=indexerCols + numericCols, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o6556.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 373.0 failed 1 times, most recent failure: Lost task 0.0 in stage 373.0 (TID 906, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<_16Index:double,_17Index:double,_18Index:double,_19Index:double,_20Index:double,_21Index:double,_22Index:double,_23Index:double,_24Index:double,_25Index:double,_26Index:double,_27Index:double,_28Index:double,_29Index:double,_30Index:double,_31Index:double,_32Index:double,_33Index:double,_34Index:double,_35Index:double,_36Index:double,_37Index:double,_38Index:double,_39Index:double,... 15 more fields>) => vector)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Values to assemble cannot be null.\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:163)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:146)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:146)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3195)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3192)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3253)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3192)\n\tat sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<_16Index:double,_17Index:double,_18Index:double,_19Index:double,_20Index:double,_21Index:double,_22Index:double,_23Index:double,_24Index:double,_25Index:double,_26Index:double,_27Index:double,_28Index:double,_29Index:double,_30Index:double,_31Index:double,_32Index:double,_33Index:double,_34Index:double,_35Index:double,_36Index:double,_37Index:double,_38Index:double,_39Index:double,... 15 more fields>) => vector)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Values to assemble cannot be null.\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:163)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:146)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:146)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)\n\t... 19 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9f23af671f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselectedCols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \"\"\"\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o6556.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 373.0 failed 1 times, most recent failure: Lost task 0.0 in stage 373.0 (TID 906, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<_16Index:double,_17Index:double,_18Index:double,_19Index:double,_20Index:double,_21Index:double,_22Index:double,_23Index:double,_24Index:double,_25Index:double,_26Index:double,_27Index:double,_28Index:double,_29Index:double,_30Index:double,_31Index:double,_32Index:double,_33Index:double,_34Index:double,_35Index:double,_36Index:double,_37Index:double,_38Index:double,_39Index:double,... 15 more fields>) => vector)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Values to assemble cannot be null.\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:163)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:146)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:146)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3195)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3192)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3253)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3192)\n\tat sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$3: (struct<_16Index:double,_17Index:double,_18Index:double,_19Index:double,_20Index:double,_21Index:double,_22Index:double,_23Index:double,_24Index:double,_25Index:double,_26Index:double,_27Index:double,_28Index:double,_29Index:double,_30Index:double,_31Index:double,_32Index:double,_33Index:double,_34Index:double,_35Index:double,_36Index:double,_37Index:double,_38Index:double,_39Index:double,... 15 more fields>) => vector)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Values to assemble cannot be null.\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:163)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:146)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:146)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:99)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$3.apply(VectorAssembler.scala:98)\n\t... 19 more\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "\n",
    "selectedCols = ['output', 'features'] + cols\n",
    "df = df.select(selectedCols)\n",
    "\n",
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
